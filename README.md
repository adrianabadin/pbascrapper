# Normas GBA - Scraper + Embedder + MCP Server

Sistema completo para scrapear, procesar y exponer la normativa de la Provincia de Buenos Aires como herramientas MCP (Model Context Protocol), permitiendo que Claude u otros asistentes puedan hacer consultas legislativas en lenguaje natural.

## Descripci√≥n general

Este proyecto integra tres componentes principales:

1. **Scraper**: Descarga leyes, decretos, resoluciones y otras normas desde [normas.gba.gob.ar](https://normas.gba.gob.ar) con paginaci√≥n mes a mes para superar l√≠mites de 200 resultados por query
2. **Embedder**: Genera embeddings sem√°nticos con OpenAI `text-embedding-3-large` (2048 dimensiones) y clasifica autom√°ticamente las normas en categor√≠as tem√°ticas con Zhipu
3. **MCP Server**: Expone 5 herramientas para consulta legislativa compatible con Claude y otros asistentes

El sistema est√° dise√±ado para asuntos legislativos pr√°cticos: proponer ordenanzas municipales, analizar qu√© normas provinciales aplican a situaciones concretas, e identificar mecanismos de adhesi√≥n municipal en la legislaci√≥n provincial.

Cobertura completa: **~568.426 normas** procesadas (leyes, decretos, resoluciones, disposiciones, ordenanzas generales, decreto-leyes y resoluciones conjuntas).

## Requisitos previos

- Node.js 18+
- PostgreSQL 17+ con extensiones `pgvector`, `uuid-ossp` y `pg_trgm`
- API key de OpenAI (para embeddings con `text-embedding-3-large`)
- API key de Zhipu AI (para clasificaci√≥n autom√°tica y fallback)
- Acceso de lectura a https://normas.gba.gob.ar

## Instalaci√≥n

```bash
# Clonar o descargar el proyecto
cd /ruta/a/pba

# Instalar dependencias
npm install

# Crear archivo .env (ver secci√≥n de Configuraci√≥n)
cp .env.example .env
# Editar .env con tus credenciales reales
```

## Configuraci√≥n

Crear un archivo `.env` en la ra√≠z del proyecto con las variables requeridas:

```bash
# Base de datos PostgreSQL
DATABASE_URL=postgresql://usuario:contrase√±a@localhost:5432/normas_gba

# API OpenAI (para embeddings)
OPENAI_API_KEY=sk-proj-...

# API Zhipu AI (para clasificaci√≥n autom√°tica)
ZHIPU_API_KEY=tu_api_key_aqui
ZHIPU_BASE_URL=https://open.bigmodel.cn/api/paas/v4

# Scraper - Paginaci√≥n y delays
SCRAPER_DELAY_MS=500                    # Delay entre requests (respetar l√≠mites del servidor)

# Embedder
EMBED_BATCH_SIZE=50                     # Items procesados por ciclo
EMBED_DELAY_MS=200                      # Delay entre batches
EMBED_POLL_INTERVAL=30000               # Espera cuando la cola est√° vac√≠a (ms)
MAX_ITEMS_API=100                       # M√°ximo items por request a OpenAI
MAX_TEXTO_CHARS=6000                    # Caracteres m√°ximos por texto (~2000 tokens)
CLASIFICAR=1                            # 0 para deshabilitar clasificaci√≥n autom√°tica durante scraping masivo

# Clasificador diferido
CLASSIFY_DELAY_MS=2000                  # Delay entre llamadas (~30 RPM)
CLASSIFY_BATCH_SIZE=100                 # Items procesados por ciclo
```

## Base de datos

Inicializar PostgreSQL con el schema:

```bash
# Conectar a PostgreSQL y ejecutar el schema
psql -U usuario -d normas_gba -f db/schema.sql

# (Opcional) Si ya existe la BD, aplicar migraciones de jerarqu√≠a normativa
node db/apply-schema.js
```

El schema incluye:
- Tabla `normas`: Informaci√≥n general con campos nuevos: `titulo`, `organismo`, `rango_normativo`, `nombre_codigo`
- Tabla `articulos`: Art√≠culos individuales con embeddings
- Tabla `relaciones_normativas`: Relaciones entre normas (modifica, deroga, reglamenta, etc.)
- Tabla `cola_embeddings`: Cola de procesamiento para el embedder (generada autom√°ticamente por triggers)
- √çndices HNSW para b√∫squeda sem√°ntica y Full-Text Search en Spanish

### Nuevas columnas

- **`titulo`** (TEXT): Nombre can√≥nico de la norma
- **`organismo`** (TEXT): Ministerio/organismo emisor para resoluciones y disposiciones (ej: "del Ministerio de H√°bitat y Desarrollo Urbano")
- **`rango_normativo`** (smallint, default 5): Jerarqu√≠a normativa
  - 1 = Constituci√≥n Provincial
  - 2 = C√≥digo provincial
  - 3 = Ley / Decreto-Ley
  - 4 = Decreto
  - 5 = Resoluci√≥n / Disposici√≥n / Resoluci√≥n Conjunta
  - 6 = Ordenanza General
- **`nombre_codigo`** (TEXT): Nombre del c√≥digo si es un c√≥digo provincial (ej: "C√≥digo Fiscal")

### Migraciones incluidas

- `db/migrations/001_jerarquia_normativa.sql`: Agrega rango_normativo y nombre_codigo
- `db/migrations/002_titulo_organismo.sql`: Agrega titulo y organismo

### Scripts de utilidad

```bash
# Asignar rangos normativos a todas las normas
node db/seed-jerarquia.js

# Resetear todos los embeddings (para regenerar con nuevo modelo)
node db/reset-embeddings.js

# Truncate de todas las tablas (cuidado!)
node db/reset-tables.js
```

## Uso

### 1. Scraper - Descargar normas

```bash
# Scraping b√°sico: todos los 7 tipos (ley, decreto, decreto_ley, ordenanza_general, resolucion, disposicion, resolucion_conjunta)
npm run scrape

# Scrapear un tipo espec√≠fico
npm run scrape -- --tipo ley
npm run scrape -- --tipo decreto
npm run scrape -- --tipo resolucion
npm run scrape -- --tipo disposicion
npm run scrape -- --tipo ordenanza_general
npm run scrape -- --tipo decreto_ley
npm run scrape -- --tipo resolucion_conjunta

# Scrapear desde un mes espec√≠fico (paginaci√≥n mes a mes)
npm run scrape -- --desde-fecha 2020-01
npm run scrape -- --desde-fecha 2020-01 --hasta-fecha 2020-06

# Combinar filtros
npm run scrape -- --tipo ley --desde-fecha 2015-01 --max-paginas 5

# Solo obtener listing (sin scraping de detalle ni texto)
npm run scrape -- --solo-listing

# Scraping masivo sin clasificaci√≥n autom√°tica (recomendado para volumen alto)
CLASIFICAR=0 npm run scrape
# Luego, ejecutar clasificador diferido despu√©s:
npm run classify
```

**Tipos de normas disponibles y cobertura total:**
- **Leyes**: ~13.942
- **Decreto-leyes**: ~2.479
- **Decretos**: ~185.905
- **Ordenanzas generales**: ~369
- **Resoluciones**: ~251.001
- **Disposiciones**: ~83.249
- **Resoluciones conjuntas**: ~31.481
- **TOTAL: ~568.426 normas**

**Argumentos CLI:**
- `--tipo`: Especificar un tipo (ley, decreto, etc.). Por defecto corre los 7 tipos en orden.
- `--desde-fecha YYYY-MM`: Mes desde el cual comenzar (default: 2000-01). Reemplaza antiguo `--desde YYYY`.
- `--hasta-fecha YYYY-MM`: Mes hasta el cual scrapear (default: mes actual).
- `--solo-listing`: Solo obtener listing sin scraping de detalle.
- `--max-paginas N`: M√°ximo n√∫mero de p√°ginas a procesar (para pruebas r√°pidas).

**C√≥mo funciona la paginaci√≥n:**

El sitio normas.gba.gob.ar limita a 20 p√°ginas (200 resultados) por query. El scraper implementa:
1. **Paginaci√≥n mes a mes**: Divide autom√°ticamente por rango de fechas mes a mes usando `q[date_ranges][publication_date][gte/lte]`
2. **Fallback semanal**: Si un mes supera 200 normas, divide autom√°ticamente en 4 semanas (01-07, 08-14, 15-21, 22-fin), recuperando hasta 800 normas/mes
3. Cada norma pasa por tres fases: upsert b√°sico ‚Üí p√°gina de detalle ‚Üí extracci√≥n de art√≠culos y relaciones normativas

**Campos guardados nuevos:**
- `titulo`: Nombre can√≥nico de la norma
- `organismo`: Ministerio emisor (solo para resoluciones/disposiciones)
- `rango_normativo`: Jerarqu√≠a normativa (asignado por seed-jerarquia.js)

### 2. Embedder - Generar embeddings y clasificar

```bash
# Procesar la cola de embeddings (embeddings + clasificaci√≥n autom√°tica)
npm run embed
```

El embedder:
- Consume la tabla `cola_embeddings` (generada autom√°ticamente por triggers del scraper)
- Genera vectores sem√°nticos con modelo **OpenAI `text-embedding-3-large`** (2048 dimensiones)
- Clasifica autom√°ticamente cada norma en categor√≠as tem√°ticas con Zhipu `glm-4.7-flash`
- Implementa reintentos autom√°ticos para rate limiting (429) y errores de red
- Procesa en batches configurables (50 items por defecto), permitiendo Ctrl+C para terminar limpiamente
- Soporta pausar/resumir autom√°ticamente cuando la cola est√° vac√≠a

**Categor√≠as tem√°ticas** (clasificaci√≥n autom√°tica):
- urbanismo
- medio_ambiente
- salud
- educacion
- tributos
- seguridad
- obras_publicas
- empleo
- municipal
- civil
- administrativo
- transporte
- vivienda
- agropecuario
- derechos_sociales
- presupuesto

**Para scraping masivo (recomendado):**
1. Scrapear con `CLASIFICAR=0` (desabilita clasificaci√≥n autom√°tica)
2. Regenerar embeddings: `node db/reset-embeddings.js`
3. Ejecutar embedder: `npm run embed`
4. Ejecutar clasificador diferido: `npm run classify`

### 3. Clasificador diferido

```bash
# Clasificar normas sin area_tematica (despu√©s de scraping masivo)
npm run classify
```

El clasificador diferido:
- Procesa normas que a√∫n no tienen `area_tematica` asignada
- Rate limiting conservador: 2000ms entre llamadas (~30 RPM)
- Reanudable: saltea normas ya clasificadas
- Muestra progreso y tiempo estimado restante
- Variables configurables: `CLASSIFY_DELAY_MS`, `CLASSIFY_BATCH_SIZE`

### 4. MCP Server - Exponer herramientas a Claude

```bash
# Iniciar el servidor MCP
npm run mcp
```

El servidor MCP se comunica por stdin/stdout y expone 5 herramientas que Claude puede usar autom√°ticamente.

#### Configurar en editores (VSCode, Cursor, etc.)

En `.claude/config.json` o similar:

```json
{
  "mcpServers": {
    "normas-gba": {
      "command": "node",
      "args": ["/ruta/completa/a/pba/mcp-server/index.js"],
      "env": {
        "DATABASE_URL": "postgresql://...",
        "OPENAI_API_KEY": "...",
        "ZHIPU_API_KEY": "..."
      }
    }
  }
}
```

En Cursor, usar la pesta√±a "MCP" en la sidebar.

## Herramientas MCP

El servidor expone 5 herramientas para Claude:

### 1. `buscar_normas` - B√∫squeda sem√°ntica de normas

Busca normas por descripci√≥n en lenguaje natural, combinando embeddings con filtros opcionales.

**Par√°metros:**
- `consulta` (string, requerido): Descripci√≥n de la situaci√≥n o tema
- `tipo` (enum): `ley` | `decreto` | `decreto_ley` | `resolucion` | `disposicion` | `ordenanza_general` | `resolucion_conjunta`
- `anio_desde` (number): A√±o m√≠nimo (1820-2100)
- `anio_hasta` (number): A√±o m√°ximo
- `categorias` (array): Filtrar por categor√≠as (ej: `["urbanismo", "medio_ambiente"]`)
- `solo_vigentes` (boolean): Excluir normas derogadas
- `limit` (number): 1-20 (default: 10)

**Ejemplo de uso en Claude:**
```
¬øQu√© leyes regulan la construcci√≥n de viviendas multifamiliares?
¬øHay normas sobre eficiencia energ√©tica en edificios?
¬øCu√°les son las normas de seguridad en works p√∫blicas desde 2010?
```

### 2. `buscar_articulos` - B√∫squeda de art√≠culos espec√≠ficos

Busca art√≠culos individuales dentro de normas, devolviendo el texto exacto del art√≠culo y la norma que lo contiene.

**Par√°metros:**
- `consulta` (string, requerido): Descripci√≥n de lo que debe decir el art√≠culo
- `tipo_norma` (enum, opcional): Limitar a un tipo espec√≠fico
- `limit` (number): 1-20 (default: 10)

**Ejemplo de uso en Claude:**
```
¬øQu√© art√≠culo habla sobre los plazos de respuesta para reclamos?
¬øCu√°l es el art√≠culo que establece multas por incumplimiento?
¬øQu√© norma dice que los municipios pueden adherir?
```

### 3. `encontrar_adhesiones` - Mecanismos de adhesi√≥n municipal

Busca art√≠culos con mecanismos que permitan a los municipios adherir o actuar mediante ordenanza local.

**Par√°metros:**
- `tema` (string, requerido): Tema sobre el que se busca adhesi√≥n (ej: "eficiencia energ√©tica")
- `limit` (number): 1-20 (default: 10)

**Ejemplo de uso en Claude:**
```
¬øQu√© ley provincial permite que los municipios adhieran a programas de residuos?
¬øHay mecanismos de adhesi√≥n para normativas de agua potable?
¬øQu√© leyes habilitan a los intendentes a dictar ordenanzas sobre urbanismo?
```

Busca frases como:
- "los municipios podr√°n adherir"
- "el intendente queda facultado"
- "mediante ordenanza municipal"
- "podr√°n adherirse al presente r√©gimen"

### 4. `obtener_norma` - Obtener norma completa

Devuelve el texto completo de una norma con todos sus art√≠culos.

**Par√°metros:**
- `tipo` (enum, requerido): Tipo de la norma
- `numero` (number, requerido): N√∫mero de la norma
- `anio` (number, requerido): A√±o de sanci√≥n (1820-2100)

**Ejemplo de respuesta:**
```json
{
  "id": "uuid",
  "tipo": "ley",
  "numero": 11723,
  "anio": 1995,
  "vigencia": "vigente",
  "area_tematica": ["urbanismo", "medio_ambiente"],
  "resumen": "...",
  "total_articulos": 45,
  "articulos": [
    {
      "numero": "1",
      "titulo": "Objeto",
      "texto": "..."
    }
  ]
}
```

### 5. `obtener_relaciones` - √Årbol de relaciones normativas

Devuelve qu√© normas modifica/deroga esta norma, y cu√°les la modifican/derogan a ella.

**Par√°metros:**
- `tipo` (enum, requerido)
- `numero` (number, requerido)
- `anio` (number, requerido)

**Tipos de relaciones:**
- `modifica`: La norma A modifica art√≠culos espec√≠ficos de la norma B
- `deroga`: La norma A deroga completamente la norma B
- `deroga_parcialmente`: Deroga solo algunos art√≠culos
- `reglamenta`: La norma A reglamento la implementaci√≥n de la norma B
- `complementa`: Complementa o ampl√≠a la norma B
- `prorroga`: Pr√≥rroga plazos de la norma B
- `sustituye`: Sustituye completamente a la norma B
- `cita`: Hace referencia a la norma B
- `otra`: Otra relaci√≥n no clasificada

## Flujo de trabajo legislativo

### Caso de uso: Proponer una ordenanza municipal

1. **Identificar el tema** ("gesti√≥n de residuos s√≥lidos", "eficiencia energ√©tica", etc.)

2. **Buscar normas provinciales aplicables**:
   - Usar `buscar_normas` para encontrar leyes y decretos relacionados
   - Leer el resumen y categor√≠a tem√°tica de cada resultado

3. **Encontrar mecanismo de adhesi√≥n**:
   - Usar `encontrar_adhesiones` con el tema
   - Identificar qu√© ley provincial permite que el municipio act√∫e mediante ordenanza

4. **Obtener texto completo de la norma base**:
   - Usar `obtener_norma` para obtener todos los art√≠culos
   - Analizar qu√© requisitos impone la ley provincial

5. **Verificar vigencia y modificaciones**:
   - Usar `obtener_relaciones` para asegurar que la norma no est√° derogada
   - Identificar si hay normas m√°s recientes que la completen

6. **Redactar la ordenanza municipal**:
   - Basarse en el texto provincial
   - Adaptar a la realidad local
   - Asegurar coherencia con la normativa superior
   - Usar Claude + ambos MCPs (GBA y Saladillo) para validar propuesta

### Workflow para producci√≥n (scraping masivo)

Cuando se requiere procesar todas las ~568.426 normas o una porci√≥n significativa:

```bash
# 1. Scraping masivo sin clasificaci√≥n autom√°tica
CLASIFICAR=0 npm run scrape

# 2. Resetear embeddings para regenerar con nuevo modelo OpenAI
node db/reset-embeddings.js

# 3. Generar embeddings con OpenAI text-embedding-3-large
npm run embed

# 4. Clasificar normas diferidamente (despu√©s de embeddings)
npm run classify

# 5. Opcionalmente, asignar rangos normativos si es primera vez
node db/seed-jerarquia.js
```

Este flujo optimiza costos evitando clasificaciones fallidas durante el scraping inicial.

### Ejemplo concreto

Proponer una ordenanza municipal sobre "paneles solares en viviendas":

```
Claude + MCP GBA:
1. Buscar: "regulaci√≥n de energ√≠a renovable paneles solares"
2. Encontrar adhesiones: "energ√≠a renovable"
3. Obtener texto completo: ley 14.146/2010 (ley de energ√≠as renovables)
4. Verificar vigencia: obtener_relaciones

Claude + MCP Saladillo (ordenanzas locales):
5. Buscar ordenanzas anteriores sobre construcci√≥n, licencias
6. Validar que no entren en conflicto

Resultado:
‚Üí Redactar nueva ordenanza municipal sobre paneles solares,
  respaldada por la ley provincial y sin conflictos con ordenanzas locales
```

## Estructura del proyecto

```
pba/
‚îú‚îÄ‚îÄ README.md                        # Este archivo
‚îú‚îÄ‚îÄ package.json
‚îú‚îÄ‚îÄ .env.example                     # Template de variables de entorno
‚îú‚îÄ‚îÄ db/
‚îÇ   ‚îú‚îÄ‚îÄ schema.sql                   # Schema PostgreSQL con todas las tablas
‚îÇ   ‚îú‚îÄ‚îÄ apply-schema.js              # Aplicar schema a BD existente
‚îÇ   ‚îú‚îÄ‚îÄ reset-tables.js              # Truncate CASCADE de todas las tablas
‚îÇ   ‚îú‚îÄ‚îÄ reset-embeddings.js          # NUEVO: resetear embeddings
‚îÇ   ‚îú‚îÄ‚îÄ seed-jerarquia.js            # NUEVO: asignar rango_normativo
‚îÇ   ‚îî‚îÄ‚îÄ migrations/
‚îÇ       ‚îú‚îÄ‚îÄ 001_jerarquia_normativa.sql    # NUEVO
‚îÇ       ‚îî‚îÄ‚îÄ 002_titulo_organismo.sql       # NUEVO
‚îú‚îÄ‚îÄ scraper/
‚îÇ   ‚îú‚îÄ‚îÄ index.js                     # CLI principal del scraper
‚îÇ   ‚îú‚îÄ‚îÄ crawler.js                   # Funciones HTTP y parsing HTML
‚îÇ   ‚îú‚îÄ‚îÄ parser.js                    # Parsing de listings y p√°ginas de detalle
‚îÇ   ‚îú‚îÄ‚îÄ db.js                        # Operaciones sobre la BD
‚îÇ   ‚îú‚îÄ‚îÄ embedder.js                  # Procesador de embeddings y clasificaci√≥n
‚îÇ   ‚îî‚îÄ‚îÄ clasificador.js              # NUEVO: clasificador diferido
‚îú‚îÄ‚îÄ mcp-server/
‚îÇ   ‚îî‚îÄ‚îÄ index.js                     # Servidor MCP con 5 herramientas
‚îî‚îÄ‚îÄ tests/
    ‚îî‚îÄ‚îÄ *.test.js                    # Tests unitarios con Jest
```

## Desarrollo

### Ejecutar tests

```bash
npm test
```

### Ver logs del scraper

El scraper imprime el progreso en tiempo real:

```
üîç Scrapeando LEY (desde 2024-01)...
   Total: 13942 normas, paginaci√≥n mes a mes + fallback semanal
üìÑ Mes 2024-01...
  ‚Üí Semana 01-07: 25 normas procesadas
  ‚Üí Semana 08-14: 18 normas procesadas
  ‚Üí Semana 15-21: 22 normas procesadas
  ‚Üí Semana 22-31: 35 normas procesadas
  [Total mes 2024-01: 100 normas ‚úì]
```

### Ver logs del embedder

El embedder muestra estad√≠sticas por batch:

```
[10:23:45] Batch #1: 50 items
  ‚Üí Normas (embedding + clasificaci√≥n): 40
  ‚Üí Art√≠culos (embedding): 10
  [sub-batch 1] 16 textos, 8234 chars... OK (2456 tokens OpenAI)
  [sub-batch 2] 16 textos, 7891 chars... OK (2187 tokens OpenAI)
  ‚Üí Embeddings: 50/50 guardados, 0 errores, 4643 tokens, 3.2s
  ‚Üí Clasificados: 40/40 normas, 12.5s
  Acumulado: 15234 embeddings, 12456 clasificaciones, 125432 tokens OpenAI
```

## Limitaciones y consideraciones

### Alcance de datos

- El scraper descarga solo normas disponibles en normas.gba.gob.ar
- No incluye sentencias judiciales, fallos, o normativa anterior a 1820
- El sitio web puede cambiar su estructura, requiriendo actualizaci√≥n del parser
- La paginaci√≥n mes a mes y fallback semanal garantizan cobertura completa

### Costos de API

**Embeddings:**
- OpenAI `text-embedding-3-large`: ~$0.13 USD por 1M tokens (2048 dimensiones)
- Procesamiento de ~568.426 normas + 2M art√≠culos: estimado ~$15-25 USD

**Clasificaci√≥n:**
- Zhipu `glm-4.7-flash`: ~$0.001 USD por 1K tokens (gratuito para muchos niveles)
- Clasificar ~568.426 normas: estimado ~$1-3 USD

**Total estimado para volumen completo: ~$20-30 USD**

### Rate limiting

- El servidor de normas.gba.gob.ar limita a ~500ms entre requests
- OpenAI API: sin l√≠mite espec√≠fico de rate limiting en text-embedding (muy r√°pido)
- Zhipu API: rate limiting manejado autom√°ticamente con reintentos exponenciales
- Ajustar `SCRAPER_DELAY_MS` si se obtienen errores 429 del sitio

## Troubleshooting

### "ERROR: DATABASE_URL no est√° definida"
- Verificar que el archivo `.env` existe en la ra√≠z del proyecto
- Asegurar que la variable `DATABASE_URL` est√° correctamente formada

### "ERROR: OPENAI_API_KEY no est√° definida"
- Verificar que la variable `OPENAI_API_KEY` est√° en `.env`
- Confirmar que es una clave v√°lida de OpenAI (sk-proj-...)

### Embedding falla con "429 Rate limit"
- Aumentar `EMBED_DELAY_MS` (ej: de 200 a 500)
- Reducir `EMBED_BATCH_SIZE` (ej: de 50 a 25)
- Para OpenAI generalmente no hay problemas de rate limiting, verificar cota de tokens

### Clasificaci√≥n diferida falla repetidamente
- Aumentar `CLASSIFY_DELAY_MS` (ej: de 2000 a 5000)
- Verificar que `ZHIPU_API_KEY` es v√°lida
- Revisar logs para mensajes de error espec√≠ficos de Zhipu

### Scraper se detiene en 10 errores consecutivos
- Esperar 5 minutos (el servidor puede estar temporalmente bloqueando)
- Reanudar desde donde par√≥ usando `--desde-fecha YYYY-MM`

### PostgreSQL: "pgvector extension not found"
```sql
CREATE EXTENSION IF NOT EXISTS vector;
CREATE EXTENSION IF NOT EXISTS uuid-ossp;
CREATE EXTENSION IF NOT EXISTS pg_trgm;
```

### MCP Server no se conecta
- Verificar que `DATABASE_URL`, `OPENAI_API_KEY` y `ZHIPU_API_KEY` est√°n en el entorno
- Revisar permisos de conexi√≥n a PostgreSQL
- Consultar stderr para mensajes de error del servidor

## Integraci√≥n con otros MCPs

Este proyecto se complementa con:
- **MCP Saladillo**: Ordenanzas municipales de Saladillo (https://github.com/ejemplo/saladillo-mcp)

Ambos MCPs se pueden usar simult√°neamente en Claude para validar que una nueva ordenanza municipal:
1. Se basa en norma provincial v√°lida (MCP GBA)
2. No entra en conflicto con ordenanzas locales existentes (MCP Saladillo)

## Licencia

Este proyecto est√° bajo licencia MIT.

## Contribuciones

Las contribuciones son bienvenidas. Por favor:
1. Fork el proyecto
2. Crear una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abrir un Pull Request

## Contacto

Para preguntas o sugerencias sobre este proyecto, abrir un issue en el repositorio.
